---
layout: default
---
<div class="projectPage">
    
<h3> Reconfigurable HDR]{Reconfigurable Snapshot HDR Imaging Using
 <br> <span style="height: 1.5em"></span>
    Coded Masks and Inception Network </h3>

<a href="/People/malghamdi/">Masheal Alghamdi</a>, <a href="/People/fuq/"> Qiang Fu</a>, Ali Thabit, <a href="/People/heidriw/">Wolfgang Heidrich</a>

<br> Accepted to the 24th International Symposium on Vision, Modeling and Visualization (VMV 2019).<br>
<hr size="4", color="black", width="100%">
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#results">Main results</a></li>
<li><a href="#paper">Paper</a></li>
</ul>
<hr size="4", color="black", width="100%">
    
<img src="teaser.jpg" style="width:940px;height:208px;"> <br>
Overview of the proposed HDR imaging system. In hardware a binary optical mask is placed near the image sensor to achieve spatially
varying exposures (top left). In reconstruction we first devise a casual one-time calibration network to accurately estimate the mask
(bottom left), and then input the raw noisy color filter array (CFA) image and estimated mask to our HDR reconstruction network to obtain
the final HDR image. The HDR-VDP-2 visibility probability maps for our result (right-top), blue indicates unperceivable differences,
which means that our system can recover a high quality HDR image from a single raw LDR image. <br><br>
  
<h4 id="abstract">Abstract</h4>
High Dynamic Range (HDR) image acquisition from a single image capture, also known as snapshot HDR imaging, is challenging because the
bit depths of camera sensors are far from sufficient to cover the full dynamic range of the scene. Existing HDR techniques focus either
on algorithmic reconstruction or hardware modification to extend the dynamic range. In this paper we propose a joint design for snapshot
HDR imaging by devising a spatially-varying modulation mask in the hardware as well as building an inception network to reconstruct the
HDR image. We achieve a reconfigurable HDR camera design that does not require custom sensors, and instead can be reconfigured between
HDR and conventional mode with very simple calibration steps. We demonstrate that the proposed hardware-software solution offers a 
flexible yet robust way to modulating per-pixel exposures, and the network requires little knowledge of the hardware to faithfully 
reconstruct the HDR image. Comparison results show that our method outperforms state of the art in terms of visual perception quality. <br><br>

<h4 id="results">Main results</h4>
<img src="results1.png" width="80%"/><br> 
(a) 2D extinction images (DBIEI) obtained at 0°, 45°, and 90° with the simultaneous LII image obtained at 117°. 
(b) 3d reconstruction of the extinction images with K multiplied by 100, and Velocity profile of the flame with units of pixels/frame. <br> <br> 
<img src="results2.png" width="80%"/> <br> 
Input 2d video (left) obtained at 0°, 45°, and 90° with the simultaneous LII image obtained at 117°, and reconstructed results (right) <br> <br> 
<img src="result3.png" width="50%"/> <br>
(Left image) Normalized LII image taken at 117°. (Right image) Normalized tomographic reconstruction image slice at 117°.<br> <br>

<h4 id="paper">Paper and Video</h4>
<pre class="tab">paper          <a href="alghamdi2019HDR.pdf">[alghamdi2019HDR.pdf (13.9MB)]</a> 
               <a href="alghamdi2019HDR_Supp.pdf">[alghamdi2019HDR_Supp.pdf (14.2MB)]</a></pre>
    
</div>

