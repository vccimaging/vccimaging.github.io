---
layout: default
---
<div class="projectPage">
<h2> Extended Depth-of-Field Projector using Learned Diffractive Optics </h2>

<a href="https://vccimaging.org/People/yuqi/">Yuqi Li</a>, <a href="/People/fuq/">Qiang Fu</a>, <a href="/People/heidriw/">Wolfgang Heidrich</a>
<br>IEEE VR 2023, the 30th IEEE Conference on Virtual Reality and 3D User Interfaces<br>


<hr size="4", color="black", width="100%">
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#paper">Paper</a></li>
<!-- <li><a href="#citation">Citation</a></li> -->
</ul>
<!-- <hr size="4", color="black", width="100%">
<img src="teaser.jpg" width="60%"/> <br>
Figure 1: We propose an end-to-end hardware-software joint optimization technique to extend the depth of field (DOF) of projectors. Instead of just algorithmically deconvolving the out-of-focus blur, we learned a custom diffractive optical element (DOE) placed in front of the projector lens. The learned DOE results in a point spread function (PSF) with higher energy concentration over a wide range of projection distances compared to normal projection using a normal lens. With jointly optimized hardware and a deep compensation network, our method can create an all-in-focus image display with sharp details on projection planes at different depths. Here are the PSFs (bottom left) and the results (right) displayed on a tilted projection screen at 50 degrees to the projection direction.
<br><br>â€‹ -->

<h4 id="abstract">Abstract</h4>
<p>Projector Depth-of-Field (DOF) refers to the projection range of projector images in focus. It is a crucial property of projectors in spatial augmented reality (SAR) applications since wide projector DOF can increase the effective projection area on the projection surfaces with large depth variances and thus reduce the number of projectors required. Existing state-of-the-art methods attempt to create all-in-focus displays by adopting either a deep deblurring network or light modulation. Unlike previous work that considers the optimization of the deblurring model and physic modulation separately, in this paper, we propose an end-to-end joint optimization method to learn a diffractive optical element (DOE) placed in front of a projector lens and a compensation network for deblurring. Using the desired image and the captured projection result image, the compensation network can directly output the compensated image for display. We evaluate the proposed method in physical simulation and with a real experimental prototype, showing that the proposed method can extend the projector DOF by a minor modification to the projector and thus superior to the normal projection with a shallow DOF. The compensation method is also compared with the state-ofthe- art methods and shows the advance in radiometric compensation in terms of computational efficiency and image quality.</p> <br><br>

<h4 id="paper">Paper</h4>
<pre class="tab">Paper <a href="Li2023VR.pdf">[Li2023VR.pdf (3.9MB)]</a></pre>

<!-- <h3 id="citation">Citation</h3>
<pre>
@article{li2023extended,
  title={Extended depth-of-field projector using learned diffractive optics},
  author={Li, Yuqi and Fu, Qiang and Heidrich, Wolfgang},
  booktitle={IEEE VR 2023, the 30th IEEE Conference on Virtual Reality and 3D User Interfaces}
  pages={1--11},
  year={2023},
  organization={IEEE}
}
</pre> -->


</div>
